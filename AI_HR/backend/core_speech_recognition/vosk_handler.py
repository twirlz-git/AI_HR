import asyncio
import time
import json
import logging
import vosk
import numpy as np
from fastapi import WebSocket
from .base_stt import BaseSTT
from .openrouter_processor import OpenRouterProcessor
from .hr_interviewer import HRInterviewer
from . import settings

logger = logging.getLogger(__name__)

class VoskHandler(BaseSTT):
    def __init__(self, model_path=settings.MODEL_PATH, chunk_duration=settings.CHUNK_DURATION):
        super().__init__(chunk_duration)
        self.model_path = model_path
        self.vosk_model = None
        self.openrouter = OpenRouterProcessor()
        self.hr_interviewer = HRInterviewer()
        self.last_speech_time = time.time()  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ—á–∏
        
    async def initialize(self):
        import os
        if not os.path.exists(self.model_path):
            logger.error(f"Model not found: {self.model_path}")
            return False
        
        self.vosk_model = vosk.Model(self.model_path)
        logger.info("Vosk model loaded")
        return True
    
    async def process_stream(self, websocket: WebSocket):
        logger.info(f"üöÄ Starting process_stream, session_active={self.session_active}")
        last_processed_time = time.time()
        self.last_speech_time = time.time()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ç—Ä–∏–±—É—Ç –∫–ª–∞—Å—Å–∞ 
        
        while self.session_active:
            try:
                current_time = time.time()
                
                if (current_time - last_processed_time) >= self.chunk_duration:
                    chunk_samples = int(self.sample_rate * self.chunk_duration)
                    
                    if len(self.pcm_buffer) >= chunk_samples:
                        audio_data = list(self.pcm_buffer)[-chunk_samples:]
                        
                        recognizer = vosk.KaldiRecognizer(self.vosk_model, self.sample_rate)
                        
                        audio_array = np.array(audio_data)
                        max_val = np.max(np.abs(audio_array))
                        
                        if max_val > 0:
                            if max_val < settings.AUDIO_AMPLIFICATION_THRESHOLD:
                                amplification = settings.AUDIO_AMPLIFICATION_THRESHOLD / max_val
                                audio_array = audio_array * amplification
                        
                        audio_bytes = (audio_array).astype(np.int16).tobytes()
                        
                        recognizer.AcceptWaveform(audio_bytes)
                        final_result = json.loads(recognizer.FinalResult())
                        
                        text = final_result.get("text", "").strip()
                        
                        if text:
                            new_text = self.deduplicate_text(text, self.segments)
                            
                            if new_text:
                                segment = {
                                    "text": new_text,
                                    "timestamp": current_time,
                                    "duration": self.chunk_duration,
                                    "confidence": final_result.get("confidence", 0.8)
                                }
                                
                                self.segments.append(segment)
                                
                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç
                                await self.send_result(websocket, segment, "vosk")
                                
                                # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –¥–ª—è OpenRouter
                                if self.accumulated:
                                    self.accumulated += settings.TEXT_SEPARATOR + new_text
                                else:
                                    self.accumulated = new_text
                                
                                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ—á–∏
                                self.last_speech_time = current_time
                        
                        last_processed_time = current_time
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏—à–∏–Ω—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                silence_duration = current_time - self.last_speech_time
                # logger.debug(f"Checking silence: accumulated='{self.accumulated}', silence={silence_duration:.1f}s, interview_active={self.hr_interviewer.interview_active}")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–ª—á–∞–Ω–∏—è –≤ –∏–Ω—Ç–µ—Ä–≤—å—é: 5 —Å–µ–∫ –º–æ–ª—á–∞–Ω–∏—è ‚Üí —Å–ø–∏–Ω–Ω–µ—Ä + –æ–±—Ä–∞–±–æ—Ç–∫–∞
                if (silence_duration >= settings.SILENCE_THRESHOLD and
                    self.hr_interviewer.interview_active):
                    
                    logger.info(f"üîÑ Silence detected ({settings.SILENCE_THRESHOLD}s), processing answer...")
                    logger.info(f"üîÑ Sending processing_started message")

                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏–Ω–Ω–µ—Ä
                    try:
                        await websocket.send_json({
                            "type": "processing_started",
                            "message": "–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Ç–≤–µ—Ç–∞..."
                        })
                        logger.info(f"üîÑ processing_started message sent")
                    except Exception as e:
                        logger.error(f"‚ùå Error sending processing_started: {e}")
                        return
                    
                    # –°–†–ê–ó–£ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
                    interview_continues = await self.finalize_session(websocket)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é
                    if not interview_continues:
                        logger.info("üèÅ Interview finished, exiting process_stream loop")
                        break
                    
                    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                    self.accumulated = ""
                    self.segments = []
                    self.last_speech_time = time.time()
                
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"Processing error: {e}")
                await asyncio.sleep(1)
        
        logger.warning(f"‚ùå process_stream loop exited! session_active={self.session_active}")
    
    
    async def finalize_session(self, websocket: WebSocket):
        """–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –≤ HR –∏–Ω—Ç–µ—Ä–≤—å—é"""
        if self.accumulated and self.accumulated.strip():
            if self.hr_interviewer.interview_active:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç –≤ —Ä–∞–º–∫–∞—Ö –∏–Ω—Ç–µ—Ä–≤—å—é
                logger.info(f"Processing answer for question {self.hr_interviewer.current_question + 1}")
                result = await self.hr_interviewer.process_answer(self.accumulated)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥
                try:
                    await websocket.send_json(result)
                    logger.info("Answer processed, result sent")
                except Exception as e:
                    logger.error(f"‚ùå Error sending result: {e}")
                    return
                
                # –í–ê–ñ–ù–û: –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                self.accumulated = ""
                self.last_speech_time = time.time()
                
                # –ù–ï –û–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú –û–ë–†–ê–ë–û–¢–ö–£ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–ª—É—à–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç–≤–µ—Ç
                # self.stop_processing()
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å –∏–Ω—Ç–µ—Ä–≤—å—é
                return self.hr_interviewer.interview_active
        else:
            logger.info("No text to process")
            if self.hr_interviewer.interview_active:
                # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–ª—á–∞–ª - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
                logger.info("Processing silence as empty answer in interview")
                result = await self.hr_interviewer.process_answer("–ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ–º–æ–ª—á–∞–ª")
                try:
                    await websocket.send_json(result)
                    logger.info("Silence processed, result sent")
                except Exception as e:
                    logger.error(f"‚ùå Error sending silence result: {e}")
                    return
                
                # –í–ê–ñ–ù–û: –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                self.accumulated = ""
                self.last_speech_time = time.time()
                
                # –ù–ï –û–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú –û–ë–†–ê–ë–û–¢–ö–£ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–ª—É—à–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç–≤–µ—Ç
                # self.stop_processing()
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å –∏–Ω—Ç–µ—Ä–≤—å—é
                return self.hr_interviewer.interview_active
        
        # –ï—Å–ª–∏ –Ω–µ –±—ã–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∏–Ω—Ç–µ—Ä–≤—å—é –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è
        return True
    
    def reset_speech_timer(self):
        """Reset speech timer to current time"""
        self.last_speech_time = time.time()
    
    def stop_processing(self):
        """Stop current processing session"""
        self.session_active = False
        logger.info("üõë –ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
    
    def is_model_loaded(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å"""
        return self.vosk_model is not None